{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Azure Machine Learning resources in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "from azureml.core import ComputeTarget\n",
    "\n",
    "print(\"Compute Resources:\")\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(\"\\t\", compute.name, ':', compute.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get  Prediction from Automated ML Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "endpoint = 'ENDPOINT' #Replace with your endpoint\n",
    "key = 'PRIMARY_KEY' #Replace with your key\n",
    "\n",
    "#Features for a patient\n",
    "x = [{\"PatientID\": 1,     \"Pregnancies\": 5,     \"PlasmaGlucose\": 181.0,     \"DiastolicBloodPressure\": 90.6,     \"TricepsThickness\": 34.0,     \"SerumInsulin\": 23.0,     \"BMI\": 43.51,     \"DiabetesPedigree\": 1.21,     \"Age\": 21.0}]\n",
    "\n",
    "#Create a \"data\" JSON object\n",
    "input_json = json.dumps({\"data\": x})\n",
    "\n",
    "#Set the content type and authentication for the request\n",
    "headers = {\"Content-Type\":\"application/json\",\"Authorization\":\"Bearer \" + key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(endpoint, str.encode(input_json), headers=headers)\n",
    "y = json.loads(response.json())\n",
    "print(\"Prediction:\", y[\"result\"][0])#Get the first prediction in the results\n",
    "    \n",
    "print('Diabetic') if (y[\"result\"][0] == 1) else print(\"Not Diabetic\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions from a Designer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(endpoint, input_json, headers)\n",
    "response = urllib.request.urlopen(req)\n",
    "json_result = json.loads(response.read())\n",
    "output = json_result[\"Results\"][\"WebServiceOutput0\"][0]\n",
    "print('Patient: {}\\nPrediction: {}\\nProbability: {:.2f}'\n",
    "      .format(output[\"PatientID\"],output[\"DiabetesPrediction\"],output[\"Probability\"],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve experiment details using the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View run details\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    The Details tab contains the general properties of the experiment run.\n",
    "    The Metrics tab enables you to select logged metrics and view them as tables or charts.\n",
    "    The Images tab enables you to select and view any images or plots that were logged in the experiment (in this case, the Label Distribution plot)\n",
    "    The Child Runs tab lists any child runs (in this experiment there are none).\n",
    "    The Outputs + Logs tab shows the output or log files generated by the experiment.\n",
    "    The Snapshot tab contains all files in the folder where the experiment code was run (in this case, everything in the same folder as this notebook).\n",
    "    The Explanations tab is used to show model explanations generated by the experiment (in this case, there are none).\n",
    "    The Fairness tab is used to visualize predictive performance disparities that help you evaluate the fairness of machine learning models (in this case, there are none).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = run.get_metrics() \n",
    "[print(metric_name, \":\", metrics[metric_name]) for metric_name in metrics] \n",
    "files = run.get_file_names()\n",
    "[print(file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder = 'downloaded-files'\n",
    "\n",
    "# Download files in the \"outputs\" folder\n",
    "run.download_files(prefix='outputs', output_directory=download_folder)\n",
    "for root, directories, filenames in os.walk(download_folder): \n",
    "    [print (os.path.join(root,filename))  for filename in filenames]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_details_with_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  to download the log files and view them in a text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run.get_all_logs(destination='downloaded-logs')\n",
    "\n",
    "# Verify the files have been downloaded\n",
    "for root, directories, filenames in os.walk(log_folder): \n",
    "[print (os.path.join(root,filename)) for filename in filenames] \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View experiment run history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_experiment = ws.experiments['diabetes-experiment']\n",
    "for logged_run in diabetes_experiment.get_runs():\n",
    "    print('Run ID:', logged_run.id)\n",
    "    metrics = logged_run.get_metrics()\n",
    "    [print('-', key, metrics.get(key)) for key in metrics.keys()]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Use MLflow\n",
    "MLflow is an open source platform for managing machine learning processes. It's commonly (but not exclusively) used in Databricks environments to coordinate experiments and track metrics. In Azure Machine Learning experiments, you can use MLflow to track metrics as an alternative to the native log functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $folder_name/mlflow_diabetes.py\n",
    "from azureml.core import Run\n",
    "import mlflow\n",
    "\n",
    "# start the MLflow experiment\n",
    "with mlflow.start_run():\n",
    "     mlflow.log_metric('observations', row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "mlflow_env = Environment(\"mlflow-env\")\n",
    "\n",
    "# Ensure the required packages are installed\n",
    "packages = CondaDependencies.create(conda_packages=['pandas','pip'],\n",
    "                                    pip_packages=['mlflow','azureml-mlflow'])\n",
    "mlflow_env.python.conda_dependencies = packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a script config\n",
    "script_mlflow = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='mlflow_diabetes.py',\n",
    "                                environment=mlflow_env) \n",
    "\n",
    "# submit the experiment\n",
    "experiment = Experiment(workspace=ws, name='diabetes-mlflow-script')\n",
    "run = experiment.submit(config=script_mlflow)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = run.get_metrics()\n",
    "[print(key, metrics.get(key)) for key in metrics.keys()]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure automated machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.train.automl.utilities as automl_utils\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "[ print(metric) for metric in automl_utils.get_primary_metrics('classification')]\n",
    "    \n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(name='Automated ML Experiment',\n",
    "                             task='classification',\n",
    "                             compute_target=training_cluster,\n",
    "                             training_data = train_ds,\n",
    "                             validation_data = test_ds,\n",
    "                             label_column_name='Diabetic',\n",
    "                             iterations=4,\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             max_concurrent_iterations=2,\n",
    "                             featurization='auto'\n",
    "                             )\n",
    "\n",
    "print(\"Ready for Auto ML run.\")\n",
    "\n",
    "automl_experiment = Experiment(ws, 'diabetes_automl')\n",
    "automl_run = automl_experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_run.get_output()\n",
    "print(best_run),print(fitted_model)\n",
    "\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "[print(metric_name, best_run_metrics[metric_name]) for metric_name in best_run_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Differential Privacy\n",
    "Differential privacy is a technique that is designed to preserve the privacy of individual data points by adding \"noise\" to the data. \n",
    "SmartNoise aims to provide building blocks for using differential privacy in data analysis and machine learning projects.\n",
    "\n",
    "\n",
    "\n",
    "The histograms are similar enough to ensure that reports based on the differentially private data provide the same insights as reports from the raw data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendp.smartnoise.core as sn\n",
    "\n",
    "cols = list(diabetes.columns)\n",
    "age_range = [0.0, 120.0]\n",
    "samples = len(diabetes)\n",
    "\n",
    "with sn.Analysis() as analysis:\n",
    "    data = sn.Dataset(path=data_path, column_names=cols)    # load data\n",
    "    age_dt = sn.to_float(data['Age']) # Convert Age to float\n",
    "    age_mean = sn.dp_mean(data = age_dt,   # get mean of age\n",
    "                          privacy_usage = {'epsilon': .50},\n",
    "                          data_lower = age_range[0],  data_upper = age_range[1], data_rows = samples  )\n",
    "    \n",
    "\n",
    "    age_histogram = sn.dp_histogram(\n",
    "            sn.to_int(data['Age'], lower=0, upper=120),\n",
    "            edges = ages,upper = 10000, null_value = -1,\n",
    "            privacy_usage = {'epsilon': 0.5})\n",
    "    \n",
    "    age_bp_cov_scalar = sn.dp_covariance(\n",
    "                left = sn.to_float(sn_data['Age']),\n",
    "                right = sn.to_float(sn_data['DiastolicBloodPressure']),\n",
    "                privacy_usage = {'epsilon': 1.0},\n",
    "                left_lower = 0.,left_upper = 120.,left_rows = 10000,\n",
    "                right_lower = 0., right_upper = 150., right_rows = 10000)\n",
    "analysis.release()\n",
    "\n",
    "# print ifferentially private estimate of mean age ad actual mean age\n",
    "print(age_mean.value,diabetes.Age.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendp.smartnoise.metadata import CollectionMetadata\n",
    "from opendp.smartnoise.sql import PandasReader, PrivateReader\n",
    "\n",
    "meta = CollectionMetadata.from_file('metadata/diabetes.yml')\n",
    "private_reader = PrivateReader(meta, reader, 5.0)  # large epsilon, less privacy# smaller epsilon, more privacy\n",
    "\n",
    "\n",
    "query = 'SELECT Diabetic, AVG(Age) AS AvgAge FROM diabetes.diabetes GROUP BY Diabetic'\n",
    "result_dp = private_reader.execute_typed(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get a list of datasets from the workspace object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, 'version', dataset.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Run an experiment on remote compute\n",
    "\n",
    "Now you're ready to re-run the experiment you ran previously, but this time on the compute cluster you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
    "                                environment=registered_env,\n",
    "                                compute_target=cluster_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_state = training_cluster.get_status()\n",
    "print(cluster_state.allocation_state, cluster_state.current_node_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the Azure Machine Learning extension for Azure DevOps to combine Azure ML pipelines with Azure DevOps pipelines (yes, it is confusing that they have the same name!) and integrate model retraining into a continuous integration/continuous deployment (CI/CD) process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned.\n",
    "\n",
    "model = ws.models['diabetes_model']\n",
    "script_file = os.path.join(experiment_folder,\"score_diabetes.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an entry script (often called a scoring script) that will be deployed to the web service:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a hyperparameter tuning experiment\n",
    "Azure Machine Learning includes a hyperparameter tuning capability through hyperdrive experiments. These experiments launch multiple child runs, each with a different hyperparameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core import Model\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "sklearn_env = Environment(\"sklearn-env\")\n",
    "\n",
    "# Ensure the required packages are installed (we need scikit-learn, Azure ML defaults, and Azure ML dataprep)\n",
    "packages = CondaDependencies.create(pip_packages=['scikit-learn','azureml-defaults','azureml-dataprep[pandas]'])\n",
    "sklearn_env.python.conda_dependencies = packages\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
    "                                environment=sklearn_env,\n",
    "                                compute_target = training_cluster)\n",
    "\n",
    "# Sample a range of parameter values\n",
    "params = GridParameterSampling(\n",
    "    {\n",
    "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
    "        '--learning_rate': choice(0.01, 0.1, 1.0),\n",
    "        '--n_estimators' : choice(10, 100)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure hyperdrive settings\n",
    "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
    "                          hyperparameter_sampling=params, \n",
    "                          policy=None, # No early stopping policy\n",
    "                          primary_metric_name='AUC', # Find the highest AUC metric\n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=6, # Restict the experiment to 6 iterations\n",
    "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
    "\n",
    "# Run the experiment\n",
    "experiment = Experiment(workspace = ws, name = 'diabates_training_hyperdrive')\n",
    "run = experiment.submit(config=hyperdrive)\n",
    "\n",
    "# Show the status in the notebook as the experiment runs\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()\n",
    "\n",
    "\n",
    "# Register model\n",
    "best_run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                        tags={'Training context':'Hyperdrive'},\n",
    "                        properties={'AUC': best_run_metrics['AUC'], 'Accuracy': best_run_metrics['Accuracy']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
